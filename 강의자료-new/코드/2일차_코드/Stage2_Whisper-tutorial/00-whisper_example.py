import openai
import sounddevice as sd
import scipy.io.wavfile as wav
import tempfile
import os
import uuid
from playsound import playsound  # mp3 ì¬ìƒìš©

# OpenAI API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
# ë°˜ë“œì‹œ ë³¸ì¸ì˜ OpenAI API í‚¤ë¡œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
os.environ["OPENAI_API_KEY"] = (
    ""
)
# ì˜¤ë””ì˜¤ ë…¹ìŒ ì„¤ì •
SAMPLERATE = 16000  # ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ë ˆì´íŠ¸(Hz)
DURATION = 3  # ë…¹ìŒ ê¸¸ì´(ì´ˆ)


def record_audio():
    """
    ë§ˆì´í¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•©ë‹ˆë‹¤.
    ì…ë ¥: ì—†ìŒ
    ì¶œë ¥: ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°(numpy array)
    ë™ì‘:
        - ì§€ì •ëœ ìƒ˜í”Œë ˆì´íŠ¸ì™€ ê¸¸ì´ë¡œ ë§ˆì´í¬ ì…ë ¥ì„ ë…¹ìŒí•©ë‹ˆë‹¤.
        - ë…¹ìŒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.
    """
    print("ğŸ™ï¸ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(
        int(SAMPLERATE * DURATION), samplerate=SAMPLERATE, channels=1, dtype="int16"
    )
    sd.wait()  # ë…¹ìŒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
    return audio


# Whisper API í˜¸ì¶œ (ìµœì‹  openai>=1.0.0 ë°©ì‹)
def transcribe(audio_data):
    """
    Whisper APIë¥¼ ì‚¬ìš©í•´ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì…ë ¥: audio_data (numpy array, ë…¹ìŒëœ ì˜¤ë””ì˜¤)
    ì¶œë ¥: ë³€í™˜ëœ í…ìŠ¤íŠ¸(str)
    ë™ì‘:
        - ì„ì‹œ wav íŒŒì¼ë¡œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        - Whisper APIì— íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        - ì„ì‹œ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
        wav.write(temp_wav.name, SAMPLERATE, audio_data)
        temp_wav_path = temp_wav.name

    with open(temp_wav_path, "rb") as file:
        transcript = openai.audio.transcriptions.create(
            model="whisper-1", file=file, language="ko"
        )

    os.remove(temp_wav_path)
    return transcript.text


# TTSë¡œ ìŒì„± ìƒì„± ë° ì¬ìƒ
def speak(text):
    print(f"ğŸ—£ï¸ speak(): {text}")
    response = openai.audio.speech.create(
        model="tts-1",
        voice="shimmer",
        # ["alloy", "ash", "coral", "echo", "fable", "onyx", "nova", "sage", "shimmer", "verse"] ê°€ëŠ¥
        input=text,
    )
    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as audio_file:
        audio_file.write(response.content)
        audio_file.flush()
        audio_path = audio_file.name

    playsound(audio_path)
    os.remove(audio_path)

# ëŒ€í™” íë¦„ì„ ê´€ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
def main():
    """
    ìŒì„± ì¸ì‹ ë° TTSë¥¼ í™œìš©í•œ ê°„ë‹¨í•œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    ì…ë ¥: ì—†ìŒ
    ì¶œë ¥: ì—†ìŒ
    ë™ì‘:
        - 'ì‹œì‘'ì´ë¼ëŠ” ìŒì„± ëª…ë ¹ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        - 'ì‹œì‘'ì´ ê°ì§€ë˜ë©´ ì¸ì‚¬ ë° ì„ íƒì§€ ì•ˆë‚´ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
        - ì´í›„ 'ì½œë¼' ë˜ëŠ” 'ì‚¬ì´ë‹¤' ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ìŒì„±ì„ ì¶œë ¥í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤.
    """
    print("ğŸ¤ ë§ˆì´í¬ê°€ ì¼œì¡ŒìŠµë‹ˆë‹¤. 'ì‹œì‘'ì´ë¼ê³  ë§í•˜ì„¸ìš”.")
    state = "waiting"

    while True:
        audio_data = record_audio()
        text = transcribe(audio_data)
        print(f"ğŸ“ ì¸ì‹ëœ ë§: {text}")

        if state == "waiting" and "ì‹œì‘" in text:
            speak("ì•ˆë…•í•˜ì„¸ìš”. ìíŒê¸°ì…ë‹ˆë‹¤. ì½œë¼ì™€ ì‚¬ì´ë‹¤ ì¤‘ ë¬´ì—‡ì„ ì›í•˜ì„¸ìš”?")
            state = "waiting_for_selection"

        elif state == "waiting_for_selection":
            if "ì½œë¼" in text:
                speak("ì½œë¼ë¥¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                break
            elif "ì‚¬ì´ë‹¤" in text:
                speak("ì‚¬ì´ë‹¤ë¥¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                break


if __name__ == "__main__":
    main()
