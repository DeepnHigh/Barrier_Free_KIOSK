import openai
from openai import OpenAI
import sounddevice as sd
import scipy.io.wavfile as wav
import tempfile
import os
from playsound import playsound # mp3 ì¬ìƒìš©
import uuid # For generating unique filenames

os.environ["OPENAI_API_KEY"] = (
    ""
)
client = OpenAI()
initial_prompt1 = """
    ### ì—­í• 
    ë‹¹ì‹ ì€ ë§¤ìš° ë°œë„í•œ ê³ ë“±í•™êµ 1í•™ë…„ ì—¬í•™ìƒì…ë‹ˆë‹¤. ì„œë¡œë¥¼ ì†Œê°œí•˜ëŠ” ëŒ€í™”ë¥¼ ì§„í–‰í•´ ì£¼ì„¸ìš”.
    
    ### ëª©í‘œ
    ë‹¹ì‹ ì´ ì•Œì•„ë‚´ì•¼ í•  ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    1) ì´ë¦„ 2) ì„±ë³„ 3) ë‚˜ì´ 4) í•™êµ
    ëª¨ë‘ ì•Œì•„ë‚¸ ë‹¤ìŒ, ì•Œì•„ë‚¸ ë‚´ìš©ì„ ì •ë¦¬í•´ì„œ ì–˜ê¸°í•´ì£¼ì„¸ìš”. 
    
    ### ì£¼ì˜ì‚¬í•­
    ì§ˆë¬¸ì€ í•˜ë‚˜ì”© í•´ì£¼ì„¸ìš”.
    ì´ëª¨í‹°ì½˜ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš” 
"""

# TTSë¡œ ìŒì„± ìƒì„± ë° ì¬ìƒ
def speak(text):
    print(f"ğŸ—£ï¸ speak(): {text}")
    response = openai.audio.speech.create(
        model="tts-1",
        voice="shimmer",
        input=text,
    )
    
    # Generate a unique filename in the current working directory
    # This avoids potential issues with long or complex tempfile paths
    unique_filename = f"temp_audio_{uuid.uuid4().hex}.mp3"
    audio_path = os.path.join(os.getcwd(), unique_filename)

    try:
        with open(audio_path, "wb") as audio_file:
            audio_file.write(response.content)
        
        playsound(audio_path)
    except Exception as e:
        print(f"Error playing audio with playsound: {e}")
        print("Please check if the path is valid and if an appropriate MP3 player is associated with .mp3 files.")
    finally:
        if os.path.exists(audio_path):
            os.remove(audio_path) # Clean up the temporary file


# ìŒì„± ë…¹ìŒ
SAMPLERATE = 16000
DURATION = 3


def record_audio():
    print("ğŸ™ï¸ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(
        int(SAMPLERATE * DURATION), samplerate=SAMPLERATE, channels=1, dtype="int16"
    )
    sd.wait()
    return audio


# Whisper API í˜¸ì¶œ (ìµœì‹  openai>=1.0.0 ë°©ì‹)
def transcribe(audio_data):
    # Using tempfile for recording is generally safer as playsound isn't involved
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
        wav.write(temp_wav.name, SAMPLERATE, audio_data)
        temp_wav_path = temp_wav.name

    with open(temp_wav_path, "rb") as file:
        transcript = openai.audio.transcriptions.create(
            model="whisper-1", file=file, language="ko"
        )

    os.remove(temp_wav_path)
    return transcript.text


def ask(question, message_history=[], model="gpt-3.5-turbo"):
    if len(message_history) == 0:
        # ìµœì´ˆ ì§ˆë¬¸
        message_history.append(
            {
                "role": "system",
                "content": initial_prompt1,
            }
        )

    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    message_history.append(
        {
            "role": "user",
            "content": question,
        },
    )

    # GPTì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±
    completion = client.chat.completions.create(
        model=model,
        messages=message_history,
    )

    # ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì¶”ê°€
    message_history.append(
        {"role": "assistant", "content": completion.choices[0].message.content}
    )

    return message_history


# ë©”ì¸ ë£¨í”„
def main():
    message_history = ask("ì•ˆë…•í•˜ì„¸ìš”?", message_history=[])
    speak(message_history[-1]["content"])

    while True:
        audio_data = record_audio()
        user_text = transcribe(audio_data)
        print(f"ğŸ“ ì¸ì‹ëœ ë§: {user_text}")
        message_history = ask(user_text, message_history=message_history)
        speak(message_history[-1]["content"])


if __name__ == "__main__":
    main()