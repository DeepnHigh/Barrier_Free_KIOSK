import openai
from openai import OpenAI
import sounddevice as sd
import scipy.io.wavfile as wav
import tempfile
import os
from playsound import playsound  # mp3 ì¬ìƒìš©

os.environ["OPENAI_API_KEY"] = (
    ""
)
client = OpenAI()
initial_prompt1 = """
    ### ì—­í• 
    ë‹¹ì‹ ì€ ë§¤ìš° ë°œë„í•œ ê³ ë“±í•™êµ 1í•™ë…„ ì—¬í•™ìƒì…ë‹ˆë‹¤. ì„œë¡œë¥¼ ì†Œê°œí•˜ëŠ” ëŒ€í™”ë¥¼ ì§„í–‰í•´ ì£¼ì„¸ìš”.
    
    ### ëª©í‘œ
    ë‹¹ì‹ ì´ ì•Œì•„ë‚´ì•¼ í•  ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    1) ì´ë¦„ 2) ì„±ë³„ 3) ë‚˜ì´ 4) í•™êµ
    ëª¨ë‘ ì•Œì•„ë‚¸ ë‹¤ìŒ, ì•Œì•„ë‚¸ ë‚´ìš©ì„ ì •ë¦¬í•´ì„œ ì–˜ê¸°í•´ì£¼ì„¸ìš”. 
    
    ### ì£¼ì˜ì‚¬í•­
    ì§ˆë¬¸ì€ í•˜ë‚˜ì”© í•´ì£¼ì„¸ìš”.
    ì´ëª¨í‹°ì½˜ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”  
"""


# TTSë¡œ ìŒì„± ìƒì„± ë° ì¬ìƒ
def speak(text):
    print(f"ğŸ—£ï¸ speak(): {text}")
    response = openai.audio.speech.create(
        model="tts-1",
        voice="shimmer",
        input=text,
    )
    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as audio_file:
        audio_file.write(response.content)
        audio_file.flush()
        audio_path = audio_file.name

    playsound(audio_path)
    os.remove(audio_path)


# ìŒì„± ë…¹ìŒ
SAMPLERATE = 16000
DURATION = 3


def record_audio():
    print("ğŸ™ï¸ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(
        int(SAMPLERATE * DURATION), samplerate=SAMPLERATE, channels=1, dtype="int16"
    )
    sd.wait()
    return audio


# Whisper API í˜¸ì¶œ (ìµœì‹  openai>=1.0.0 ë°©ì‹)
def transcribe(audio_data):
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
        wav.write(temp_wav.name, SAMPLERATE, audio_data)
        temp_wav_path = temp_wav.name

    with open(temp_wav_path, "rb") as file:
        transcript = openai.audio.transcriptions.create(
            model="whisper-1", file=file, language="ko"
        )

    os.remove(temp_wav_path)
    return transcript.text


def ask(question, message_history=[], model="gpt-3.5-turbo"):
    if len(message_history) == 0:
        # ìµœì´ˆ ì§ˆë¬¸
        message_history.append(
            {
                "role": "system",
                "content": initial_prompt1,
            }
        )

    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    message_history.append(
        {
            "role": "user",
            "content": question,
        },
    )

    # GPTì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±
    completion = client.chat.completions.create(
        model=model,
        messages=message_history,
    )

    # ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì¶”ê°€
    message_history.append(
        {"role": "assistant", "content": completion.choices[0].message.content}
    )

    return message_history


# ë©”ì¸ ë£¨í”„
def main():
    message_history = ask("ì•ˆë…•í•˜ì„¸ìš”?", message_history=[])
    speak(message_history[-1]["content"])

    while True:
        audio_data = record_audio()
        user_text = transcribe(audio_data)
        print(f"ğŸ“ ì¸ì‹ëœ ë§: {user_text}")
        message_history = ask(user_text, message_history=message_history)
        speak(message_history[-1]["content"])


if __name__ == "__main__":
    main()
