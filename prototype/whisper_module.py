import sounddevice as sd
import scipy.io.wavfile as wav
import tempfile
import os
import openai
import pyttsx3
from difflib import get_close_matches
import re

# OpenAI API ì„¤ì •
client = openai.OpenAI(api_key="")  # ë˜ëŠ” os.environ["OPENAI_API_KEY"]

# TTS ì„¤ì •
engine = pyttsx3.init()
engine.setProperty("rate", 150)
engine.setProperty("volume", 1.0)
engine.setProperty("voice", engine.getProperty("voices")[0].id)

def speak(text):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥"""
    print(f"ğŸ—£ï¸ {text}")
    engine.say(text)
    engine.runAndWait()

# ìŒì„± ë…¹ìŒ ì„¤ì •
SAMPLERATE = 16000
DURATION = 5

def record_audio():
    """ìŒì„± ë…¹ìŒ"""
    print("ğŸ™ï¸ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(int(SAMPLERATE * DURATION), samplerate=SAMPLERATE, channels=1, dtype='int16')
    sd.wait()
    return audio

def transcribe(audio_data):
    """Whisperë¡œ ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
        wav.write(temp_file.name, SAMPLERATE, audio_data)
        temp_file.close()

        with open(temp_file.name, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ko"
            )

        os.unlink(temp_file.name)
    return transcript.text.strip()
