import sounddevice as sd
import scipy.io.wavfile as wav
import tempfile
import os
import openai
import pyttsx3


# OpenAI API
client = openai.OpenAI(api_key="")  # ë˜ëŠ” os.environ["OPENAI_API_KEY"]

initial_prompt = """
ë‹¹ì‹ ì€ ì¹´í˜ì˜ ì¹œì ˆí•œ ì§ì›ì…ë‹ˆë‹¤.
ë‹¤ìŒ ìˆœì„œì— ë”°ë¼ì„œ ì£¼ë¬¸ì„ ë°›ìœ¼ë©´ ë©ë‹ˆë‹¤.

[1ë‹¨ê³„]
- [ì»¤í”¼, ì°¨, ì—ì´ë“œ, ìŠ¤ë¬´ë””] ë©”ë‰´ ì¤‘ í•˜ë‚˜ë¥¼ ì£¼ë¬¸ë°›ìœ¼ë©´ ë©ë‹ˆë‹¤.

[2ë‹¨ê³„]
- ë©”ë‰´ê°€ ì»¤í”¼ì´ë©´ [ì•„ë©”ë¦¬ì¹´ë…¸, ë¼ë–¼] ì¤‘ í•˜ë‚˜ë¥¼ ì£¼ë¬¸ë°›ìœ¼ì„¸ìš”.
- ë©”ë‰´ê°€ ì°¨ ì´ë©´ [ìºëª¨ë§ˆì¼, ì–¼ê·¸ë ˆì´] ì¤‘ í•˜ë‚˜ë¥¼ ì£¼ë¬¸ë°›ìœ¼ì„¸ìš”.
- ë©”ë‰´ê°€ ì—ì´ë“œ ì´ë©´ [ì²­í¬ë„, ë ˆëª¬] ì¤‘ í•˜ë‚˜ë¥¼ ì£¼ë¬¸ë°›ìœ¼ì„¸ìš”.
- ë©”ë‰´ê°€ ìŠ¤ë¬´ë”” ì´ë©´ [ë”¸ê¸°, ë§ê³ ] ì¤‘ í•˜ë‚˜ë¥¼ ì£¼ë¬¸ë°›ìœ¼ì„¸ìš”.

[3ë‹¨ê³„]
- ë©”ë‰´ê°€ [ì»¤í”¼, ì°¨] ì¤‘ í•˜ë‚˜ì¼ ê²½ìš° [ì•„ì´ìŠ¤, í•«] ì¤‘ í•˜ë‚˜ë¥¼ ì£¼ë¬¸ë°›ìœ¼ì„¸ìš”.
- ë©”ë‰´ê°€ [ì—ì´ë“œ, ìŠ¤ë¬´ë””] ì¤‘ í•˜ë‚˜ì¼ ê²½ìš° ê±´ë„ˆë›°ë©´ ë©ë‹ˆë‹¤.

[4ë‹¨ê³„]
- ì¶”ê°€ ì£¼ë¬¸ì„ í•  ê±´ì§€ ë¬»ê³ , ì£¼ë¬¸í•  ê²½ìš° í˜„ì¬ì˜ ë©”ë‰´ë¥¼ ê¸°ì–µí•˜ê³  [1ë‹¨ê³„]ë¡œ ëŒì•„ê°€ì„¸ìš”.
- ì¶”ê°€ ì£¼ë¬¸ì´ ì—†ì„ ê²½ìš° í˜„ì¬ì˜ ë©”ë‰´ë¥¼ ê¸°ì–µí•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ì„¸ìš”.

[5ë‹¨ê³„]
{ì•„ë©”ë¦¬ì¹´ë…¸:2500, ë¼ë–¼:3000, ìºëª¨ë§ˆì¼:2700, ì–¼ê·¸ë ˆì´:2700, ì²­í¬ë„:3200, ë ˆëª¬:3200, ë”¸ê¸°:3500, ë§ê³ :3500}
- ìœ„ ê¸ˆì•¡ ì±…ì •ì— ë”°ë¼ ì´ ê¸ˆì•¡ì„ ê³„ì‚°í•˜ì„¸ìš”.
- ì´ ê¸ˆì•¡ì„ ë§í•˜ê³  ì£¼ë¬¸í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤ ë¼ê³  ë§í•˜ì„¸ìš”.
- ë§¨ ë§ˆì§€ë§‰ ë§ë¡œ 'ì¢…ë£Œí•©ë‹ˆë‹¤' ë¥¼ ë°˜ë“œì‹œ ë§í•˜ì„¸ìš”.


"""

# TTS
engine = pyttsx3.init()
engine.setProperty("rate", 150)
engine.setProperty("volume", 1.0)
engine.setProperty("voice", engine.getProperty("voices")[0].id)
 
def speak(text):
    print(f"ğŸ—£ï¸ {text}")
    engine.say(text)
    engine.runAndWait()

# ìŒì„± ë…¹ìŒ
SAMPLERATE = 16000
DURATION = 5

def record_audio():
    print("ğŸ™ï¸ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(int(SAMPLERATE * DURATION), samplerate=SAMPLERATE, channels=1, dtype='int16')
    sd.wait()
    return audio

def transcribe(audio_data):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
        wav.write(temp_file.name, SAMPLERATE, audio_data)
        temp_file.close()
        with open(temp_file.name, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ko"
            )
        os.unlink(temp_file.name)
    return transcript.text.strip()

def ask(question, message_history=[], model="o4-mini-2025-04-16"):
    if len(message_history) == 0:
        # ìµœì´ˆ ì§ˆë¬¸
        message_history.append(
            {
                "role": "system",
                "content": initial_prompt,
            }
        )

    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    message_history.append(
        {
            "role": "user",
            "content": question,
        },
    )

    # GPTì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±
    completion = client.chat.completions.create(
        model=model,
        messages=message_history,
    )

    # ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì¶”ê°€
    message_history.append(
        {"role": "assistant", "content": completion.choices[0].message.content}
    )

    return message_history


# ë©”ì¸ ë£¨í”„
def main():
    message_history = ask("ì•ˆë…•í•˜ì„¸ìš”?", message_history=[])
    speak(message_history[-1]["content"])

    
    while True:
        audio_data = record_audio()
        user_text = transcribe(audio_data)
        print(f"ğŸ“ ì¸ì‹ëœ ë§: {user_text}")
        message_history = ask(user_text, message_history=message_history)
        speak(message_history[-1]["content"])
        

        if any(x in message_history[-1]["content"] for x in ["ì¢…ë£Œ", "ë", "ê·¸ë§Œ", "ê²°ì œ", "ì£¼ë¬¸ ë", "ì£¼ë¬¸ ì™„ë£Œ", "ë‹¤ í–ˆì–´"]):
            break

if __name__ == "__main__":
    main()
